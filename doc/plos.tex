% Template for PLoS
% Version 1.0 January 2009
%
% To compile to pdf, run:
% latex plos.template
% bibtex plos.template
% latex plos.template
% latex plos.template
% dvipdf plos.template

\documentclass[10pt]{article}

% amsmath package, useful for mathematical formulas
\usepackage{amsmath}
% amssymb package, useful for mathematical symbols
\usepackage{amssymb}

% graphicx package, useful for including eps and pdf graphics
% include graphics with the command \includegraphics
\usepackage{graphicx}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

\usepackage{color}

% Use doublespacing - comment out for single spacing
\usepackage{setspace}
\doublespacing


% Text layout
\topmargin 0.0cm
\oddsidemargin 0.5cm
\evensidemargin 0.5cm
\textwidth 16cm
\textheight 21cm

% Bold the 'Figure #' in the caption and separate it with a period
% Captions will be left justified
\usepackage[labelfont=bf,labelsep=period,justification=raggedright]{caption}

% Use the PLoS provided bibtex style
\bibliographystyle{plos2009}

% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother


% Leave date blank
\date{}

\pagestyle{myheadings}
%% ** EDIT HERE **


%% ** EDIT HERE **
%% PLEASE INCLUDE ALL MACROS BELOW

\newcommand{\hmic}{{IC}$_{50}$}
\newcommand{\idepi}{{IDEPI}}
\newcommand{\hiv}{{HIV}-1}
\newcommand{\N}{\emph{N}}
\newcommand{\mrmr}{{mRMR}}
\newcommand{\svm}{{SVM}}

%% END MACROS SECTION

\begin{document}

% Title must be 150 characters or less
\begin{flushleft}
{\Large
\textbf{\idepi{}: rapid prediction of \hiv{} antibody epitopes leveraging mutual information and support vector machines}
}
% Insert Author names, affiliations and corresponding author email.
\\
N Lance Hepler$^{1,\ast}$,
Konrad Scheffler$^{2}$,
Douglas D Richman$^{2,3}$,
Dennis R Burton$^{4,5}$,
Sergei L Kosakovsky Pond$^{2}$
\\
\bf{1} Interdisciplinary Bioinformatics and Systems Biology Program, University of California San Diego, La Jolla, California, USA
\\
\bf{2} Department of Medicine, University of California San Diego, La Jolla, California, USA
\\
\bf{3} San Diego Veterans Affairs Healthcare System, San Diego, California, USA
\\
\bf{4} The Scripps Research Institute, La Jolla, California, USA
\\
\bf{5} Ragon Institute of {MGH}, {MIT}, and Harvard, Boston, Massachusetts, USA
\\
$\ast$ E-mail: Corresponding nhepler@ucsd.edu
\end{flushleft}

% Please keep the abstract between 250 and 300 words
\section*{Abstract}

% Please keep the Author Summary between 150 and 200 words
% Use first person. PLoS ONE authors please skip this step.
% Author Summary not valid for PLoS ONE submissions.
\section*{Author Summary}

\section*{Introduction}

%Introduced in the late 20th century,
%the human immunodeficiency virus type 1 (\hiv{}) has infected approximately 60 million people
%and caused approximately 25 million deaths.
%The advent of highly active antiretroviral therapy ({HAART}) has contributed greatly to the struggle against the \hiv{} epidemic.
%Unfortunately, HAART is neither curative, nor uniformly effective, nor widely available.
%These facts have reinforced the need for a preventative and potentially curative vaccine.
%Unfortunately, such a vaccine has remained elusive.
%This is largely due to the combination of \hiv{}'s mutational speed,
%its proclivity for genomic recombination events,
%and the unique and heterogeneous structure of its envelope protein (env),
%all of which render \hiv{} infections resistant to immunological suppression.
%Recently, the discovery of several broadly neutralizing antibodies (bnAbs) has suggested new routes toward the invention of an effective vaccine.
%
%In order to effectively elicit the specific activity of these bnAbs,
%we must first characterize the structural surface they recognize,
%known for any given antibody as its epitope.
%This is an open and difficult problem, largely due to the structural nature of nAb epitopes.
%There are several techniques for mapping nAb epitopes, but they often come with caveats that limit or restrict their generalizability.
%For example, one such technique is a reverse genetics approach known as “alanine screening”,
%wherein each and every position of the env protein is individually mutated to an alanine,
%which is chemically inert (relative to other amino acids) while retaining chirality (unlike glycine).
%The resulting constructs are then tested for binding activity.
%Given that there are 856 amino acid positions in the \hiv{} reference sequence ({HXB2}),
%such a technique is obviously labor and resource intensive.
%Additionally, results are not guaranteed to be representative of biological reality:
%some positions cannot be realistically mutated \emph{in vivo}:
%there are fitness constraints that must be accounted for,
%and the constructs employed in binding assays are often monomeric or dimeric forms of the env protein, which is trimeric \emph{in vivo}.
%Other biochemical and structural methods suffer similar caveats:
%x-ray crystallography often requires the use of chimeric constructs to facilitate crystallization.
%In addition to the promise of rapid results, computational approaches to epitope mapping offer, somewhat paradoxically, more biologically realistic results.
%
%% talk about other computational approaches, e.g. CHAVI, possibly miguel, and others
%% talk about limitations in their approaches, either due to speed or unsimulatability
%I propose one such method here, and demonstrate its efficacy on a variety of previously-characterized bnAb epitopes.
%%, and validate its performance across a variety of simulated inputs.
%
%For a given neutralizing agent,
%the \idepi{} pipeline uses predictive modeling to identify frequent mutations characterizing sequences of low sensitivity from sequences of high sensitivity.
%We hypothesize that common compensatory mutations will often lie within the epitope.

% Results and Discussion can be combined.
\section*{Results}

%We demonstrate the effectiveness of the \idepi{} epitope prediction pipeline on the well-characterized b12 and 2F5 bnAbs,
%and offer epitope predictions for the PG9 and PG16 bnAbs and several members of the recently-discovered PGT-family of bnAbs.

%\subsection*{\idepi{} epitope predictions}

%\subsubsection*{2F5}
%For bnAb 2F5, our data is composed of 241 sequences from a variety of subtypes,
%predominantly subtype B (\N{} = 68) and C (\N{} = 49),
%with a total of 243 independent \hmic{} samples.
%Of note is that when a sequence has more than a single corresponding \hmic{},
%the largest value is assumed.
%For 101 of the samples, the \hmic{} is considered ``saturated'' with an $\textrm{{IC}}_{50} \ge 25{\mu}g/mL$.
%We threshold the \hmic{}s at $20{\mu}g/mL$,
%so that approximately 43.6\% of the samples are classified resistant.
%Using forward selection, \idepi{} determined the optimum number of features to choose is 2,
%with 10-fold cross-validation producing the following statistics on average:
%accuracy - 95.1\%,
%sensitivity - 96.3\%,
%specificity - 94.4\%,
%and F-score - 94.4\%.
%Additionally, \idepi{} identifies sequence features K665K and A667A in more than 80\% of the cross-validation folds,
%suggesting they are robust.
%These positions are within the previously-described, canonical epitope,
%validating \idepi{} for short linear epitopes like 2F5.
%
%\subsubsection*{b12}
%For bnAb b12, our data is composed of 384 sequences from a variety of subtypes,
%predominantly B (\N{} = 84) and C (\N{} = 64),
%with a total of 394 independent \hmic{} samples,
%with 70.5\% samples classified as resistant.
%Using forward selection, \idepi{} determined the optimum number of features to choose was 1,
%with 10
%
%\subsubsection*{PG9 and PG16}
%For bnAb PG9 and PG16, our data is composed of 
%
%\subsubsection*{PGT-family}



%\subsection*{Simulation studies}
%
%We also challenged \idepi{} with a variety of simulated data to characterize \idepi{}'s performance.
%We varied the number of samples,
%the ratio of resistant to susceptible samples,
%and the amount of experimental error in the \hmic{} values.
%\idepi{}'s performance in these simulations is measured in two ways:
%by F-score, which is a single measure of \idepi{}'s confidence;
%and by epitope recovery, which measures the ratio of simulated epitope positions identified by \idepi{}.
%
%As shown in figure XXX, \idepi{}'s performance steadily increases with the number of sequences.
%This is unsurprising, as increasing the number of training samples facilitates the discriminating power of \idepi{}'s \mrmr{} and \svm{} stages.
%Figure XXX shows that \idepi{}'s performance declines as the data become less balanced.
%Again, this is unsurprising: oversampling of susceptible or resistant sequences to the exclusion of the other
%hampers \idepi{}'s core machine learning algorithms,
%which are geared toward optimizing over all training data.
%To give an unsimulated example, the {VRC01} antibody is extremely potent,
%and our data reflects this: out of 111 sequences only 9 are resistant.
%The classifier \idepi{} builds for {VRC01} is trivial:
%optimimum performance is obtained by classifying all samples as susceptible (accuracy of 89\%).
%Additionally, it is unsurprising that \idepi{}'s performance also diminishes with increased experimental noise,
%as seen in figure XXX, although \idepi{} appears to be robust to a small amount of noise (approximately $ < \%$).

\section*{Discussion}



%I am always confused by these discussion sections. Please help.
%The results demonstrate the effectiveness of \idepi{} on ...

% You may title this section "Methods" or "Models".
% "Models" is not a valid title for PLoS ONE authors. However, PLoS ONE
% authors may use "Analysis"
\section*{Materials and Methods}

\subsection*{Data}
Data were obtained using a Monogram neutralization assay,
which measures the half-maximal inhibitory concentration (\hmic{})
of a neutralizing agent (monoclonal antibody or polyclonal sera) in a model system composed of a chimeric \hiv{} construct expressing a known envelope sequence.
This assay was performed for 64 distinct neutralizing agents, each against a panel of 9 to 421 envelope sequences (median 116).

\subsection*{Alignment}
{HMMER} version 3.0 was used to generate a multiple sequence alignment for the panel sequences.
Each column of this alignment can be labeled by its relative position to some reference sequence.
Here, we use HXB2. 

\subsection*{Feature engineering}
Each aligned sequence is described by a set of features, which can be arbitrary functions of the sequence itself.
For \idepi{} we have defined the features for amino-acid identity at a column,
for pairwise identity at two distinct columns,
for potential N-linked glycosylation sites (defined as an asparagine followed by any amino acid that is not a proline, followed by a serine or a threonine, followed again by any amino acid that is not proline),
and pairwise potential N-linked glycosylation sites.

\subsection*{Discretization}
The remainder of the machinery requires a discrete labeling,
so \hmic{}s are converted into binary classes using an arbitrary threshold function.
We aim to maximize biological realism and model utility, and a 20ug/mL has worked in practice.
This threshold is usually low enough to separate ``resistant'' and ``susceptible'' viruses,
and usually results in a ``balanced'' dataset (~50\% in each class) amenable to machine learning analysis.
% include a graph to demonstrate the balance of the 20ug/mL threshold

\subsection*{Model selection}
We have employed the minimum redundancy maximum relevance (\mrmr{}) feature selection heuristic to identify a fixed subset of $K$ features (a model) that is most informative of changes in \hmic{}.

\subsection*{Model evaluation}
Models are evaluated using cross-validation in a support vector machine framework, whose hyper-parameters are chosen by nested cross-validation. The number of features $K$ can then be chosen by forward selection, where $K$ begins with $1$ and is incremented until cross-validation performance is not improved. Here, we use Matthew's Correlation Coefficient to evaluate model performance.

\subsection*{Reporting}
\idepi{} reports a number of values, including various metadata (e.g. the number of sequences included, the number of features $K$, the threshold function, the number of cross-validation folds), model performance statistics, and the features employed, how often they were employed, and whether they were indicative of ``resistant'' or ``susceptible'' sequences.
% give example?

%The \idepi{} pipeline is composed of the following stages:
%1) collate the \hmic{} values and corresponding envelope sequences for our neutralizing agent of interest,
%2) iteratively construct a multiple sequence alignment from the collated sequences using the {HMMER} multiple sequence alignment tool,
%3) convert the multiple sequence alignment into a binary matrix form using a variety of ``feature functions''.% thresholding the \hmic{} values (at some natural or biologically-relevant value)
%and transforming each column of the MSA into a vector of 23 binary states representing the presence (1) or absence (0) of a given amino-acid or gap at any given position,
%4) $k$-fold cross-validate a predictive model,
%5) present cross-validation performance and the features chosen by the model as estimations of confidence and inferred epitope positions, respectively.
%
%The binary matrix form is created from ``feature functions'',
%which are indicator functions parameterized by the column of the multiple sequence alignment
%and the sequence features present. Currently, there are 4 types of feature functions including:
%1) per-position indicators of amino-acid identity (e.g. N301N),
%2) per-position-pair indicators of amino-acid identity (e.g. N301N+T303T),
%3) N-anchored indicators of a potential N-linked glycosylation site (e.g. PNGS(N160)),
%and 4) pairwise N-anchored indicators of potential N-linked glycosylation sites (e.g. PNGS(N301+N332)).
%\idepi{} is designed in a modular fashion to make the addition or removal of features a simple procedure.
%
%Predictive models are learned from training data using a feature selection algorithm,
%in this case \mrmr{}, followed by a dot-product (linear) support vector machine.
%The dot-product kernel is used in lieu of the more flexible radial basis function kernel or sigmoid kernel
%due to the interpretability of its model coefficients,
%which are nigh-uninterpretable for other kernels due to their ability to embed samples in high-dimensional spaces.
%
%The \mrmr{} algorithm is used for its high speed and capacity to greedily select still-informative features.
%The number of features $k$ is either chosen \emph{a priori},
%or by forward selection,
%which iteratively increments $k$ until cross-validation performance as measured by Matthew's Correlation Coefficient (MCC) no longer improves.
%This selects the minimum number of features necessary to achieve good performance.
%
%\idepi{} itself is implemented in the Python programming language,
%and leverages common scientific computing routines implemented in NumPy, SciPy, BioPython,
%and the Python machine-learning library Scikit-Learn.
%Functionality not immediately available was implemented in modules that are well-abstracted and reusable,
%all of which are now available via the PyPI package manager:
%sklmrmr - implements the \mrmr{} feature selection algorithm using Scikit-Learn interfaces,
%BioExt - implements miscellaneous computational biology routines not provided by BioPython.
%


% Do NOT remove this, even if you are not including acknowledgments
\section*{Acknowledgments}


%\section*{References}
% The bibtex filename
\bibliography{plos}

\section*{Figure Legends}
%\begin{figure}[!ht]
%\begin{center}
%%\includegraphics[width=4in]{figure_name.2.eps}
%\end{center}
%\caption{
%{\bf Bold the first sentence.}  Rest of figure 2  caption.  Caption
%should be left justified, as specified by the options to the caption
%package.
%}
%\label{Figure_label}
%\end{figure}


\section*{Tables}
%\begin{table}[!ht]
%\caption{
%\bf{Table title}}
%\begin{tabular}{|c|c|c|}
%table information
%\end{tabular}
%\begin{flushleft}Table caption
%\end{flushleft}
%\label{tab:label}
% \end{table}

\end{document}
